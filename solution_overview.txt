Elevator QA Challenge – Solution Overview (Architecture, Flow, and Design Choices)

This document is a smooth, end‑to‑end explanation of the codebase, the test strategy, and the engineering decisions taken to make the system testable and reliable for a QA review.

1) High‑Level Architecture

There are three runtime components and one test layer:

1.1 Elevator simulator (mock_elevator_mqtt.py)
- Publishes telemetry every 5 seconds to MQTT topic `elevator/sensor_data`.
- Listens to `elevator/command` for control commands.
- Keeps an in‑memory state: position, door_status, weight, maintenance_mode.
- Emits structured error events to `elevator/events` so tests can assert failures deterministically.

1.2 Cloud API simulator (mock_api.py)
- POST /elevator-data receives telemetry and validates the payload.
- GET /received allows inspection of received payloads (for tests and manual checks).
- POST /simulate_failure toggles “API down” mode (returns 500) to test offline buffering.

1.3 Bridge (bridge.py)
- Subscribes to MQTT telemetry and forwards it to the API.
- When API is down, it persists payloads to a local JSONL queue and retries periodically.
- The queue is restored on startup, allowing recovery from process restarts.

1.4 Test layer (Behave: features/ + steps/ + environment.py)
- Tests are written in Gherkin and executed by Behave.
- environment.py starts/stops API, elevator, and bridge so tests run end‑to‑end.
- MQTT setup runs per‑scenario (tagged with @mqtt) to avoid cross‑test contamination.
- Polling with timeout is used instead of fixed sleeps for stability.

2) End‑to‑End Flow (What Happens During a Test)

1. Elevator publishes telemetry on MQTT.
2. Bridge consumes telemetry and POSTs to the API.
3. API validates and stores messages.
4. Behave steps either:
   - subscribe to MQTT topics for real‑time assertions, or
   - call HTTP endpoints for API‑level assertions.
5. If API is down, bridge queues data and flushes when the API comes back.

3) Simulator Behavior (Key Functional Decisions)

- Errors are published as JSON events on `elevator/events` (not just printed). This makes errors observable and testable.
- Maintenance mode blocks MOVE_TO commands and returns an error event (realistic safety behavior).
- Door control commands OPEN_DOOR / CLOSE_DOOR update state deterministically (door_status is no longer randomized).
- Weight range accepts 0..1000, allowing empty elevator.

4) Behave Features – Detailed Explanation

4.1 commands_move.feature
- Validates MOVE_TO_<N> for representative floors (1, 5, 10).
- Includes idempotency: moving to the current floor should not produce errors.
- Uses MQTT telemetry (`sensor_data`) to confirm the position changed.

4.2 maintenance_mode.feature
- Toggles maintenance mode on/off and confirms state via telemetry.
- Verifies that MOVE_TO is rejected during maintenance with a specific error event.

4.3 invalid_floor.feature
- Sends out‑of‑range and invalid MOVE_TO commands.
- Confirms that invalid commands publish error events (boundary + format errors).

4.4 api_validation.feature
- Verifies API validation rules using direct HTTP calls.
- Missing required fields → 400 with “Missing fields”.
- Out‑of‑range values → 400 with “Invalid position/door_status/weight”.
- Uses Scenario Outline to test multiple edge cases without duplicated steps.

4.5 cloud_receives.feature
- Confirms that the cloud receives telemetry periodically.
- Uses polling with timeouts (e.g., “at least 2 new messages within 15s”) to reduce flakiness.

4.6 offline_buffer.feature
- Forces API down and ensures bridge queue fills with >=2 items.
- Brings API up and validates queue drains within a timeout.
- Uses polling to avoid fixed waits.

4.7 door_control.feature
- Sends OPEN_DOOR / CLOSE_DOOR and confirms door_status updates via telemetry.

5) Key Testing Strategy Choices (Why)

5.1 Observability first
- Structured error events + API inspection endpoints are essential for deterministic tests.

5.2 Edge‑case focus
- Boundary value tests (min/max/out‑of‑range) provide higher defect detection than exhaustive combinations.

5.3 Polling with timeout
- Async systems are timing‑sensitive; polling reduces flaky failures vs fixed sleeps.

5.4 Scenario‑scoped MQTT setup
- MQTT clients are created per scenario (tag @mqtt) to avoid shared state issues.

6) Changes Applied Beyond the Base Code (Summary)

This is a consolidated view of all modifications (including those beyond implementation.txt):

6.1 Dependencies and tooling
- Fixed typo in requirements file (requeriments.txt → requirements.txt).
- Added run_tests.sh to execute Behave and generate Allure results.
- README updated with current commands, workflows, and Allure viewing options.

6.2 mock_api.py updates
- Accepts weight 0..1000 (empty elevator allowed).
- Added GET /received and POST /simulate_failure for testability.

6.3 mock_elevator_mqtt.py updates
- Added error event publishing on `elevator/events`.
- Added maintenance‑mode MOVE_TO block with error event.
- Added OPEN_DOOR / CLOSE_DOOR support.
- Removed randomization of door_status to ensure deterministic door tests.

6.4 bridge.py behavior
- Implemented MQTT → API forwarding with persistent JSONL queue and retry loop.

6.5 Behave tests and steps
- Centralized test lifecycle in environment.py.
- Added MQTT helpers and robust polling helpers.
- Added idempotency, maintenance blocking, and door control scenarios.

7) How to Run (Quick Reference)

Full suite:
- ./run_tests.sh

Single feature:
- behave features/maintenance_mode.feature

Logs:
- logs/mock_api.log, logs/mock_elevator.log, logs/bridge.log

Allure report:
- allure serve ./allure-results
- or use Docker to view at http://localhost:5050

8) Final Rationale

The solution prioritizes deterministic behavior, observability, and realistic system constraints. Each component is testable in isolation, and the full end‑to‑end flow validates real integrations (MQTT + HTTP + offline buffering). This provides a solid QA demonstration of functional correctness, edge‑case handling, and system resilience.